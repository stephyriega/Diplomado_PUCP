{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the `REC0111.sav`, `RE223132.sav` and `RE516171.sav` files and their variables and values labels from this path `\"../../_data/endes/2019\"`. The name of imported files should be named as `rec_1`, `rec_2` and `rec_3` for files `REC0111.sav`, `RE223132.sav` and `RE516171.sav` respectively. The name of the variable and value labels should be `var_labels1` and `value_labels1` for `rec1`, `var_labels2` and `value_labels2` for `rec2`, and `var_labels3` and `value_labels3` for `rec3`. **Hint: See the section 3.3.4 of [the lecture 3](https://github.com/alexanderquispe/Diplomado_PUCP/blob/main/Lecture_3/Lecture_3.ipynb)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First, we import the three datasets from the given path\n",
    "rec_1 = pd.read_spss(r\"../../_data/endes/2019/REC0111.sav\")\n",
    "rec_2 = pd.read_spss(r\"../../_data/endes/2019/RE223132.sav\")\n",
    "rec_3 = pd.read_spss(r\"../../_data/endes/2019/RE516171.sav\")\n",
    "\n",
    "# Now, in order to get the labels, we can use savReaderWriter for each of the three datasets:\n",
    "import savReaderWriter as sav\n",
    "with sav.SavHeaderReader( r\"../../_data/endes/2019/REC0111.sav\", ioUtf8=True) as header:\n",
    "    metadata = header.all()\n",
    "    var_labels1 = metadata.varLabels\n",
    "    value_labels1 = metadata.valueLabels\n",
    "\n",
    "# Now we apply the variable and value labels to the imported dataset\n",
    "rec_1.attrs[ 'value_labels' ] = value_labels1\n",
    "rec_1.attrs[ 'var_labels' ] = var_labels1\n",
    "\n",
    "# Now we replicate the same steps for rec_2\n",
    "with sav.SavHeaderReader( r\"../../_data/endes/2019/RE223132.sav\", ioUtf8=True) as header:\n",
    "    metadata = header.all()\n",
    "    var_labels2 = metadata.varLabels\n",
    "    value_labels2 = metadata.valueLabels\n",
    "\n",
    "rec_2.attrs[ 'value_labels' ] = value_labels2\n",
    "rec_2.attrs[ 'var_labels' ] = var_labels2\n",
    "\n",
    "# Now we replicate the same steps for rec_3\n",
    "with sav.SavHeaderReader( r\"../../_data/endes/2019/RE516171.sav\", ioUtf8=True) as header:\n",
    "    metadata = header.all()\n",
    "    var_labels3 = metadata.varLabels\n",
    "    value_labels3 = metadata.valueLabels\n",
    "\n",
    "rec_3.attrs[ 'value_labels' ] = value_labels3\n",
    "rec_3.attrs[ 'var_labels' ] = var_labels3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Select the following columns for each data set:\n",
    "|Data|Columns|\n",
    "|---|---|\n",
    "|rec1| CASEID, V000, V001, V002, V003, V004, V007, V008, V009, V010, V011, V012, V024, V102, V120, V121, V122, V123, V124, V125, V127, V133 |\n",
    "|rec2| CASEID, V201, V218, V301, V302, V323, V323A, V325A, V326, V327, V337, V359, V360, V361, V362, V363, V364, V367, V372, V372A, V375A, V376, V376A, V379, V380 |\n",
    "|rec3| CASEID, V501, V502, V503, V504, V505, V506, V507, V508, V509, V510, V511, V512, V513, V525, V613, V714, V715 |\n",
    "\n",
    "\n",
    "Additioanlly, you should update the variables and value labels objects. They must have information only for the selected columns. The new dataframes should be name as `rec1_1`, `rec2_1`, and `rec3_1`. The new varible labels objects should be named as `new_var_labels1`, `new_var_labels2`, and `new_var_labels3`. The new value labels objects should be named as `new_value_labels1`, `new_value_labels2`, and `new_value_labels3` **Hint: Use the `loc` and column names to filter. Update the dictionary.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# FWe use the loc method in order to get the desired variables from the dataset for the three data sets\n",
    "rec1_1 = rec_1.loc[ : , [\"CASEID\", \"V000\", \"V001\", \"V002\", \"V003\", \"V004\", \"V007\", \"V008\", \"V009\", \"V010\", \"V011\", \"V012\", \"V024\", \"V102\", \"V120\", \"V121\", \"V122\", \"V123\", \"V124\", \"V125\", \"V127\", \"V133\" ]]\n",
    "\n",
    "rec2_1 = rec_2.loc[ : , ['CASEID', 'V201', 'V218', 'V301', 'V302', 'V323', 'V323A', 'V325A', 'V326', 'V327', 'V337', 'V359', 'V360', 'V361', 'V362', 'V363', 'V364', 'V367', 'V372', 'V372A', 'V375A', 'V376', 'V376A', 'V379', 'V380']]\n",
    "\n",
    "rec3_1 = rec_3.loc[ : , ['CASEID', 'V501', 'V502', 'V503', 'V504', 'V505', 'V506', 'V507', 'V508', 'V509', 'V510', 'V511', 'V512', 'V513', 'V525', 'V613', 'V714', 'V715']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Generate a new column for `rec1_1` named as `year`. It should be equal to `2019`. Also, you must update this new variable for the `var_labels` dictionary. Generate a new key for `new_var_labels1` and the value for this key should be **\"Year of the survey\"** **Hint: Use `loc` and `update` method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here we generated a variable that contains the year 2019 for all observations\n",
    "rec1_1[\"year\"] = 2019\n",
    "\n",
    "# We update the variable labels, using the update method\n",
    "var_labels1.update( {\"new_var_labels1\": \"Year of the survey\"} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Merge `rec1_1`, `rec2_1`, and `rec3_1` using **CASEID**. Name this new object as `endes_2019`. **Hint: Use [this link](https://stackoverflow.com/questions/53645882/pandas-merging-101)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First, we validate if CASEID it is unique within each data set\n",
    "(rec1_1['CASEID'].astype(str)).is_unique == (rec2_1['CASEID'].astype(str)).is_unique == (rec3_1['CASEID'].astype(str)).is_unique\n",
    "\n",
    "# Now we merge the 3 data sets using the merge method using CASEID as the id variable\n",
    "endes_2019 = rec1_1.merge( rec2_1, on =['CASEID'] , how = \"left\", validate = \"1:1\")\n",
    "endes_2019 = endes_2019.merge( rec3_1, on =['CASEID'] , how = \"left\", validate = \"1:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Unify all the `new_var_labels` in one object and `new_value_labels` in another one object. Name these two objects as `var_labels` and `value_labels`. Use them to generate new attributes for `endes_2019`. These attributes should be named as `var_labels` and `value_labels`. **Hint: Use `update` method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To unify all the variable labels and value labels, we need to use the update method\n",
    "var_labels1.update(var_labels2)\n",
    "var_labels1.update(var_labels3)\n",
    "\n",
    "# Now we generate a new dictionary with all the variable labels\n",
    "var_labels = var_labels1\n",
    "\n",
    "# Now we replicate the same process with the value labels\n",
    "value_labels1.update(value_labels2)\n",
    "value_labels1.update(value_labels3)\n",
    "value_labels = value_labels1\n",
    "\n",
    "# Finally we use attrs method to apply the labels to\n",
    "endes_2019.attrs['var_labels'] = var_labels\n",
    "endes_2019.attrs['value_labels'] = value_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Get the min, max, sd, n_obs, n_missing for the following columns **total children ever born (V201)**, **Ideal number of children (V613)**, **Husbands education-single yrs (V715)**, and **Age at first marriage (V511)**. We want a dataframe with the following columns **Variables, Min, Max, Mean, N_obs, N_missing** and sort by the number of missing rows. **Hint: Use `describe` and `pivot` methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     Variables   Min   Max       Mean    N_obs  N_missing\nV201      V201   0.0  13.0   1.781946  36922.0       1413\nV511      V511  10.0  48.0  20.463738  25881.0      12454\nV613      V613   0.0  96.0   2.455345  33311.0       5024\nV715      V715   0.0  96.0   2.455345  33311.0       5024",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Variables</th>\n      <th>Min</th>\n      <th>Max</th>\n      <th>Mean</th>\n      <th>N_obs</th>\n      <th>N_missing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>V201</th>\n      <td>V201</td>\n      <td>0.0</td>\n      <td>13.0</td>\n      <td>1.781946</td>\n      <td>36922.0</td>\n      <td>1413</td>\n    </tr>\n    <tr>\n      <th>V511</th>\n      <td>V511</td>\n      <td>10.0</td>\n      <td>48.0</td>\n      <td>20.463738</td>\n      <td>25881.0</td>\n      <td>12454</td>\n    </tr>\n    <tr>\n      <th>V613</th>\n      <td>V613</td>\n      <td>0.0</td>\n      <td>96.0</td>\n      <td>2.455345</td>\n      <td>33311.0</td>\n      <td>5024</td>\n    </tr>\n    <tr>\n      <th>V715</th>\n      <td>V715</td>\n      <td>0.0</td>\n      <td>96.0</td>\n      <td>2.455345</td>\n      <td>33311.0</td>\n      <td>5024</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# En la V613 hay strings \"Respuesta no numérica\" asociados al valor 96\n",
    "# En la V715 hay strings \"No sabe\" asociados al valor 98\n",
    "\n",
    "# First we change some strings values according to the dictionary\n",
    "endes_2019.V613.replace('Respuesta no numérica', 96, inplace=True)\n",
    "endes_2019.V715.replace('No sabe', 98, inplace=True)\n",
    "\n",
    "# Now we change the class of the values for those variables in order to make them float (to summarize it)\n",
    "endes_2019['V613'] = endes_2019['V613'].astype( float )\n",
    "endes_2019['V715'] = endes_2019['V613'].astype( float )\n",
    "\n",
    "# Now we generate the table with the describe method for the selected variables and then transpose it to make it to the asked form\n",
    "table = endes_2019.loc[: , ['V201' , 'V511', 'V613' , 'V715' ]].describe()\n",
    "table = table.T\n",
    "table['Variables'] = table.index\n",
    "\n",
    "# We transform the table with only the desired statistics\n",
    "table = table.loc[ : , ['Variables' , 'min', 'max' , 'mean' , 'count']]\n",
    "\n",
    "#\n",
    "table[\"N_missing\"] = list(endes_2019.loc[:,['V201' , 'V511', 'V613' , 'V715']].isnull().sum())\n",
    "table = table.rename(columns= {'mean' : \"Mean\" , 'min': \"Min\" , 'max' : \"Max\" , 'count' : \"N_obs\"})\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Use `endes_2019` data to generate a new object named `mean_key_vars` to find the mean of **total children ever born (V201)**, **Ideal number of children (V613)**, **Husbands education-single yrs (V715)**, and **Age at first marriage (V511)** by year and department **(V024)**. Name these columns as **mean_total_children, mean_ideal_children, mean_hb_yr_educ and mean_first_marriage**, respectively. **Hint: Use groupby and [this link](https://stackoverflow.com/questions/40901770/is-there-a-simple-way-to-change-a-column-of-yes-no-to-1-0-in-a-pandas-dataframe).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    year            V024  mean_total_childern  mean_ideal_children  \\\n0   2019         Huanuco             1.989754             2.591647   \n1   2019             Ica             1.671034             2.494357   \n2   2019           Junin             1.836656             2.199660   \n3   2019     La Libertad             1.704082             2.431468   \n4   2019      Lambayeque             1.673928             3.168783   \n5   2019            Lima             1.476121             2.277727   \n6   2019          Loreto             2.157568             2.476703   \n7   2019   Madre de Dios             1.972514             2.526173   \n8   2019        Moquegua             1.626724             2.052925   \n9   2019           Pasco             1.854436             2.526570   \n10  2019           Piura             1.812752             2.681343   \n11  2019            Puno             1.794307             2.119433   \n12  2019      San Martin             1.903340             2.493333   \n13  2019           Tacna             1.436502             2.013083   \n14  2019          Tumbes             1.756925             2.469824   \n15  2019         Ucayali             2.012258             2.388399   \n16  2019        Amazonas             1.980892             2.519355   \n17  2019          Ancash             1.771065             2.383260   \n18  2019        Apurimac             2.003463             2.391176   \n19  2019        Arequipa             1.539910             2.441390   \n20  2019        Ayacucho             1.848787             2.209026   \n21  2019       Cajamarca             1.931559             2.545923   \n22  2019          Callao             1.567164             2.313846   \n23  2019           Cusco             1.894415             2.100097   \n24  2019    Huancavelica             2.083969             4.008662   \n\n    mean_hb_yr_educ  mean_first_marriage  \n0          2.591647            19.818632  \n1          2.494357            20.747208  \n2          2.199660            20.683761  \n3          2.431468            20.774678  \n4          3.168783            20.953831  \n5          2.277727            21.946329  \n6          2.476703            18.448529  \n7          2.526173            19.467449  \n8          2.052925            21.640046  \n9          2.526570            20.395379  \n10         2.681343            20.451737  \n11         2.119433            20.398964  \n12         2.493333            18.953155  \n13         2.013083            22.065095  \n14         2.469824            19.409821  \n15         2.388399            18.985481  \n16         2.519355            19.266152  \n17         2.383260            20.591581  \n18         2.391176            20.064982  \n19         2.441390            22.304394  \n20         2.209026            20.340228  \n21         2.545923            19.610695  \n22         2.313846            21.517241  \n23         2.100097            20.283154  \n24         4.008662            19.780769  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>V024</th>\n      <th>mean_total_childern</th>\n      <th>mean_ideal_children</th>\n      <th>mean_hb_yr_educ</th>\n      <th>mean_first_marriage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2019</td>\n      <td>Huanuco</td>\n      <td>1.989754</td>\n      <td>2.591647</td>\n      <td>2.591647</td>\n      <td>19.818632</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2019</td>\n      <td>Ica</td>\n      <td>1.671034</td>\n      <td>2.494357</td>\n      <td>2.494357</td>\n      <td>20.747208</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2019</td>\n      <td>Junin</td>\n      <td>1.836656</td>\n      <td>2.199660</td>\n      <td>2.199660</td>\n      <td>20.683761</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2019</td>\n      <td>La Libertad</td>\n      <td>1.704082</td>\n      <td>2.431468</td>\n      <td>2.431468</td>\n      <td>20.774678</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2019</td>\n      <td>Lambayeque</td>\n      <td>1.673928</td>\n      <td>3.168783</td>\n      <td>3.168783</td>\n      <td>20.953831</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2019</td>\n      <td>Lima</td>\n      <td>1.476121</td>\n      <td>2.277727</td>\n      <td>2.277727</td>\n      <td>21.946329</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2019</td>\n      <td>Loreto</td>\n      <td>2.157568</td>\n      <td>2.476703</td>\n      <td>2.476703</td>\n      <td>18.448529</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2019</td>\n      <td>Madre de Dios</td>\n      <td>1.972514</td>\n      <td>2.526173</td>\n      <td>2.526173</td>\n      <td>19.467449</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2019</td>\n      <td>Moquegua</td>\n      <td>1.626724</td>\n      <td>2.052925</td>\n      <td>2.052925</td>\n      <td>21.640046</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2019</td>\n      <td>Pasco</td>\n      <td>1.854436</td>\n      <td>2.526570</td>\n      <td>2.526570</td>\n      <td>20.395379</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2019</td>\n      <td>Piura</td>\n      <td>1.812752</td>\n      <td>2.681343</td>\n      <td>2.681343</td>\n      <td>20.451737</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>2019</td>\n      <td>Puno</td>\n      <td>1.794307</td>\n      <td>2.119433</td>\n      <td>2.119433</td>\n      <td>20.398964</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>2019</td>\n      <td>San Martin</td>\n      <td>1.903340</td>\n      <td>2.493333</td>\n      <td>2.493333</td>\n      <td>18.953155</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>2019</td>\n      <td>Tacna</td>\n      <td>1.436502</td>\n      <td>2.013083</td>\n      <td>2.013083</td>\n      <td>22.065095</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>2019</td>\n      <td>Tumbes</td>\n      <td>1.756925</td>\n      <td>2.469824</td>\n      <td>2.469824</td>\n      <td>19.409821</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>2019</td>\n      <td>Ucayali</td>\n      <td>2.012258</td>\n      <td>2.388399</td>\n      <td>2.388399</td>\n      <td>18.985481</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2019</td>\n      <td>Amazonas</td>\n      <td>1.980892</td>\n      <td>2.519355</td>\n      <td>2.519355</td>\n      <td>19.266152</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>2019</td>\n      <td>Ancash</td>\n      <td>1.771065</td>\n      <td>2.383260</td>\n      <td>2.383260</td>\n      <td>20.591581</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>2019</td>\n      <td>Apurimac</td>\n      <td>2.003463</td>\n      <td>2.391176</td>\n      <td>2.391176</td>\n      <td>20.064982</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>2019</td>\n      <td>Arequipa</td>\n      <td>1.539910</td>\n      <td>2.441390</td>\n      <td>2.441390</td>\n      <td>22.304394</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>2019</td>\n      <td>Ayacucho</td>\n      <td>1.848787</td>\n      <td>2.209026</td>\n      <td>2.209026</td>\n      <td>20.340228</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>2019</td>\n      <td>Cajamarca</td>\n      <td>1.931559</td>\n      <td>2.545923</td>\n      <td>2.545923</td>\n      <td>19.610695</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>2019</td>\n      <td>Callao</td>\n      <td>1.567164</td>\n      <td>2.313846</td>\n      <td>2.313846</td>\n      <td>21.517241</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>2019</td>\n      <td>Cusco</td>\n      <td>1.894415</td>\n      <td>2.100097</td>\n      <td>2.100097</td>\n      <td>20.283154</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>2019</td>\n      <td>Huancavelica</td>\n      <td>2.083969</td>\n      <td>4.008662</td>\n      <td>4.008662</td>\n      <td>19.780769</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using gropby to sort by year and department\n",
    "mean_key_vars = endes_2019.groupby( ['year', 'V024' ] )[['V201', 'V613', 'V715', 'V511']].mean().rename(columns = {'V201' : \"mean_total_childern\" , 'V613': \"mean_ideal_children\" , 'V715': \"mean_hb_yr_educ\", 'V511': \"mean_first_marriage\"}).reset_index()\n",
    "mean_key_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Reshape `mean_key_vars` from wide to long. We want a dataframe with three columns **dpto, variables, values**. Name this object as `reshape_mean_key_vars`. **Hint: Use melt method**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            V024             variable      value\n0        Huanuco  mean_total_childern   1.989754\n1            Ica  mean_total_childern   1.671034\n2          Junin  mean_total_childern   1.836656\n3    La Libertad  mean_total_childern   1.704082\n4     Lambayeque  mean_total_childern   1.673928\n..           ...                  ...        ...\n95      Ayacucho  mean_first_marriage  20.340228\n96     Cajamarca  mean_first_marriage  19.610695\n97        Callao  mean_first_marriage  21.517241\n98         Cusco  mean_first_marriage  20.283154\n99  Huancavelica  mean_first_marriage  19.780769\n\n[100 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V024</th>\n      <th>variable</th>\n      <th>value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Huanuco</td>\n      <td>mean_total_childern</td>\n      <td>1.989754</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Ica</td>\n      <td>mean_total_childern</td>\n      <td>1.671034</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Junin</td>\n      <td>mean_total_childern</td>\n      <td>1.836656</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>La Libertad</td>\n      <td>mean_total_childern</td>\n      <td>1.704082</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Lambayeque</td>\n      <td>mean_total_childern</td>\n      <td>1.673928</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>Ayacucho</td>\n      <td>mean_first_marriage</td>\n      <td>20.340228</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>Cajamarca</td>\n      <td>mean_first_marriage</td>\n      <td>19.610695</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>Callao</td>\n      <td>mean_first_marriage</td>\n      <td>21.517241</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>Cusco</td>\n      <td>mean_first_marriage</td>\n      <td>20.283154</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>Huancavelica</td>\n      <td>mean_first_marriage</td>\n      <td>19.780769</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using melt method to generate a dataframe with the three columns asked\n",
    "reshape_mean_key_vars = pd.melt( mean_key_vars, id_vars = \"V024\" , value_vars= [\"mean_total_childern\", \"mean_ideal_children\", \"mean_hb_yr_educ\" , \"mean_first_marriage\"])\n",
    "\n",
    "reshape_mean_key_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Replicate your answers for questions 7 and 8, but in one line of code. Make it the most simple as possible. **NO HINT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            V024  year             variable      value\n0        Huanuco  2019  mean_total_childern   1.989754\n1            Ica  2019  mean_total_childern   1.671034\n2          Junin  2019  mean_total_childern   1.836656\n3    La Libertad  2019  mean_total_childern   1.704082\n4     Lambayeque  2019  mean_total_childern   1.673928\n..           ...   ...                  ...        ...\n95      Ayacucho  2019  mean_first_marriage  20.340228\n96     Cajamarca  2019  mean_first_marriage  19.610695\n97        Callao  2019  mean_first_marriage  21.517241\n98         Cusco  2019  mean_first_marriage  20.283154\n99  Huancavelica  2019  mean_first_marriage  19.780769\n\n[100 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V024</th>\n      <th>year</th>\n      <th>variable</th>\n      <th>value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Huanuco</td>\n      <td>2019</td>\n      <td>mean_total_childern</td>\n      <td>1.989754</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Ica</td>\n      <td>2019</td>\n      <td>mean_total_childern</td>\n      <td>1.671034</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Junin</td>\n      <td>2019</td>\n      <td>mean_total_childern</td>\n      <td>1.836656</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>La Libertad</td>\n      <td>2019</td>\n      <td>mean_total_childern</td>\n      <td>1.704082</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Lambayeque</td>\n      <td>2019</td>\n      <td>mean_total_childern</td>\n      <td>1.673928</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>Ayacucho</td>\n      <td>2019</td>\n      <td>mean_first_marriage</td>\n      <td>20.340228</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>Cajamarca</td>\n      <td>2019</td>\n      <td>mean_first_marriage</td>\n      <td>19.610695</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>Callao</td>\n      <td>2019</td>\n      <td>mean_first_marriage</td>\n      <td>21.517241</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>Cusco</td>\n      <td>2019</td>\n      <td>mean_first_marriage</td>\n      <td>20.283154</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>Huancavelica</td>\n      <td>2019</td>\n      <td>mean_first_marriage</td>\n      <td>19.780769</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In order to get all in one line, we need to apply the melt method to the database generated in question 7. The rest is the same as coded before\n",
    "reshape_mean_key_vars2 = pd.melt(endes_2019.loc[ : , ['V024' ,'year' , 'V201', 'V613' , 'V715' , 'V511']].groupby( [ 'V024' ,'year' ] ).mean().rename(columns = {'V201' : \"mean_total_childern\" , 'V613': \"mean_ideal_children\" , 'V715': \"mean_hb_yr_educ\", 'V511': \"mean_first_marriage\"}).reset_index(), id_vars = ['V024' ,'year'] , value_vars= [\"mean_total_childern\", \"mean_ideal_children\", \"mean_hb_yr_educ\" , \"mean_first_marriage\"] )\n",
    "reshape_mean_key_vars2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Merge `reshape_mean_key_vars` with `endes_2019`. Name this object `final_result`. **Hint: Use merge.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we need to merge the endes_2019 dataset with the reshape_mean_key_vars2 with m:m form.\n",
    "final_result = endes_2019.merge( reshape_mean_key_vars2, on =['V024', 'year'] , how = \"left\", validate = \"m:m\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "d7288e82646d3164eca24130947288f8779d11454649f2c02a5dfc42af7f324c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
