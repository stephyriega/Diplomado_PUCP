{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the `REC0111.sav`, `RE223132.sav` and `RE516171.sav` files and their variables and values labels from this path `\"../../_data/endes/2019\"`. The name of imported files should be named as `rec_1`, `rec_2` and `rec_3` for files `REC0111.sav`, `RE223132.sav` and `RE516171.sav` respectively. The name of the variable and value labels should be `var_labels1` and `value_labels1` for `rec1`, `var_labels2` and `value_labels2` for `rec2`, and `var_labels3` and `value_labels3` for `rec3`. **Hint: See the section 3.3.4 of [the lecture 3](https://github.com/alexanderquispe/Diplomado_PUCP/blob/main/Lecture_3/Lecture_3.ipynb)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Laptop\\\\Documents\\\\GitHub\\\\Diplomado_PUCP\\\\Lecture_3\\\\Assigment3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "rec_1 = pd.read_spss( r\"C:\\Users\\Laptop\\Documents\\GitHub\\Diplomado_PUCP\\_data\\endes\\2019\\REC0111.sav\")\n",
    "rec_2 = pd.read_spss( r\"C:\\Users\\Laptop\\Documents\\GitHub\\Diplomado_PUCP\\_data\\endes\\2019\\RE223132.sav\")\n",
    "rec_3 = pd.read_spss( r\"C:\\Users\\Laptop\\Documents\\GitHub\\Diplomado_PUCP\\_data\\endes\\2019\\RE516171.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting labels from sav file\n",
    "import savReaderWriter as sav\n",
    "with sav.SavHeaderReader( r\"C:\\Users\\Laptop\\Documents\\GitHub\\Diplomado_PUCP\\_data\\endes\\2019\\REC0111.sav\", ioUtf8=True) as header:\n",
    "    metadata1 = header.all()\n",
    "    value_labels1 = metadata1.valueLabels\n",
    "    \n",
    "with sav.SavHeaderReader( r\"C:\\Users\\Laptop\\Documents\\GitHub\\Diplomado_PUCP\\_data\\endes\\2019\\RE223132.sav\", ioUtf8=True) as header:\n",
    "    metadata2 = header.all()\n",
    "    value_labels2 = metadata2.valueLabels\n",
    "    \n",
    "with sav.SavHeaderReader( r\"C:\\Users\\Laptop\\Documents\\GitHub\\Diplomado_PUCP\\_data\\endes\\2019\\RE516171.sav\", ioUtf8=True) as header:\n",
    "    metadata3 = header.all()\n",
    "    value_labels3 = metadata3.valueLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding labels from sav file    \n",
    "rec_1.attrs[ 'value_labels1' ] = value_labels1\n",
    "rec_2.attrs[ 'value_labels2' ] = value_labels2\n",
    "rec_3.attrs[ 'value_labels2' ] = value_labels3\n",
    "\n",
    "rec_1.attrs[ 'var_labels1' ] = metadata1.varLabels\n",
    "rec_2.attrs[ 'var_labels2' ] = metadata2.varLabels\n",
    "rec_3.attrs[ 'var_labels3' ] = metadata3.varLabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Select the following columns for each data set:\n",
    "|Data|Columns|\n",
    "|---|---|\n",
    "|rec1| CASEID, V000, V001, V002, V003, V004, V007, V008, V009, V010, V011, V012, V024, V102, V120, V121, V122, V123, V124, V125, V127, V133 |\n",
    "|rec2| CASEID, V201, V218, V301, V302, V323, V323A, V325A, V326, V327, V337, V359, V360, V361, V362, V363, V364, V367, V372, V372A, V375A, V376, V376A, V379, V380 |\n",
    "|rec3| CASEID, V501, V502, V503, V504, V505, V506, V507, V508, V509, V510, V511, V512, V513, V525, V613, V714, V715 |\n",
    "\n",
    "\n",
    "Additioanlly, you should update the variables and value labels objects. They must have information only for the selected columns. The new dataframes should be name as `rec1_1`, `rec2_1`, and `rec3_1`. The new varible labels objects should be named as `new_var_labels1`, `new_var_labels2`, and `new_var_labels3`. The new value labels objects should be named as `new_value_labels1`, `new_value_labels2`, and `new_value_labels3` **Hint: Use the `loc` and column names to filter. Update the dictionary.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "rec1_1 = rec_1.loc[ :, ['CASEID', 'V000', 'V001','V002', 'V003', 'V004', 'V007', 'V008', 'V009', 'V010', 'V011', 'V012', 'V024', 'V102', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V127', 'V133']]\n",
    "rec2_1 = rec_2.loc[ :, ['CASEID', 'V201', 'V218','V301', 'V302', 'V323', 'V323A', 'V325A', 'V326', 'V327', 'V337', 'V359', 'V360','V361', 'V362', 'V363', 'V364', 'V367', 'V372', 'V372A', 'V375A', 'V376','V376A', 'V379', 'V380']]\n",
    "rec3_1 = rec_3.loc[ :, ['CASEID', 'V501', 'V502', 'V503', 'V504', 'V505', 'V506', 'V507', 'V508', 'V509', 'V510', 'V511', 'V512', 'V513', 'V525', 'V613', 'V714', 'V715']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "var_labels1=metadata1.varLabels\n",
    "var_labels2=metadata2.varLabels\n",
    "var_labels3=metadata3.varLabels\n",
    "\n",
    "rec_1 = ['CASEID', 'V000', 'V001','V002', 'V003', 'V004', 'V007', 'V008', 'V009', 'V010', 'V011', 'V012', 'V024', 'V102', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V127', 'V133']\n",
    "rec_2 = ['CASEID', 'V201', 'V218','V301', 'V302', 'V323', 'V323A', 'V325A', 'V326', 'V327', 'V337', 'V359', 'V360','V361', 'V362', 'V363', 'V364', 'V367', 'V372', 'V372A', 'V375A', 'V376','V376A', 'V379', 'V380']\n",
    "rec_3 = ['CASEID', 'V501', 'V502', 'V503', 'V504', 'V505', 'V506', 'V507', 'V508', 'V509', 'V510', 'V511', 'V512', 'V513', 'V525', 'V613', 'V714', 'V715']\n",
    "\n",
    "new_var_labels1 = {i: var_labels1[i] for i in rec_1}\n",
    "new_var_labels2 = {i: var_labels2[i] for i in rec_2}\n",
    "new_var_labels3 = {i: var_labels3[i] for i in rec_3}\n",
    "\n",
    "new_value_labels1 = {i: value_labels1[i] for i in rec_1 if i in value_labels1}\n",
    "new_value_labels2 = {i: value_labels2[i] for i in rec_2 if i in value_labels2}\n",
    "new_value_labels3 = {i: value_labels3[i] for i in rec_3 if i in value_labels3}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Generate a new column for `rec1_1` named as `year`. It should be equal to `2019`. Also, you must update this new variable for the `var_labels` dictionary. Generate a new key for `new_var_labels1` and the value for this key should be **\"Year of the survey\"** **Hint: Use `loc` and `update` method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos la nueva columna de año: \n",
    "rec1_1.loc[ : , 'year' ] = 2019\n",
    "rec1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Incorporamos Year al diccionario de etiquetas:\n",
    "new = {'Year': \"Year of the survey\"}\n",
    "new_var_labels1.update(new)\n",
    "new_var_labels1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Merge `rec1_1`, `rec2_1`, and `rec3_1` using **CASEID**. Name this new object as `endes_2019`. **Hint: Use [this link](https://stackoverflow.com/questions/53645882/pandas-merging-101)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validamos el tamaño de las bases\n",
    "print(rec1_1.shape)\n",
    "print(rec2_1.shape)\n",
    "print(rec3_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos primero el merge entre la base 1 y la base 2, pero considerando que la base 1 es de mayor dimensión\n",
    "# que la base 2:\n",
    "endes_2019_prelim =  rec1_1.merge( rec2_1 , on = [ 'CASEID' ] , how = \"left\" , validate = \"m:1\" )\n",
    "\n",
    "#Ahora realizamos la fusión entre el merge preliminar y la base 3, considerando lo mismo:\n",
    "endes_2019 =  endes_2019_prelim.merge( rec3_1 , on = [ 'CASEID' ] , how = \"left\" , validate = \"m:1\" )\n",
    "\n",
    "endes_2019.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Unify all the `new_var_labels` in one object and `new_value_labels` in another one object. Name these two objects as `var_labels` and `value_labels`. Use them to generate new attributes for `endes_2019`. These attributes should be named as `var_labels` and `value_labels`. **Hint: Use `update` method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procedemos a unificar los diccionarios de las variables, lo hacemos centralizando la información en el primer\n",
    "#diccionario\n",
    "\n",
    "new_var_labels1.update(new_var_labels2)\n",
    "new_var_labels1.update(new_var_labels3)\n",
    "\n",
    "var_labels = new_var_labels1.copy()\n",
    "\n",
    "#Ahora procedemos a realizar lo mismo con los valores, aplicando el comando update\n",
    "new_value_labels1.update(new_value_labels2)\n",
    "new_value_labels1.update(new_value_labels3)\n",
    "\n",
    "value_labels = new_value_labels1.copy()\n",
    "\n",
    "# Finalmente generamos los atributos en la base de datos \n",
    "endes_2019.attrs[ 'var_labels' ] = var_labels\n",
    "endes_2019.attrs[ 'value_labels' ] = value_labels\n",
    "\n",
    "# Verificamos los datos\n",
    "#endes_2019.attrs[ 'var_labels' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos los datos de las Valores:\n",
    "endes_2019.attrs[ 'value_labels' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Get the min, max, sd, n_obs, n_missing for the following columns **total children ever born (V201)**, **Ideal number of children (V613)**, **Husbands education-single yrs (V715)**, and **Age at first marriage (V511)**. We want a dataframe with the following columns **Variables, Min, Max, Mean, N_obs, N_missing** and sort by the number of missing rows. **Hint: Use `describe` and `pivot` methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscamos y contamos los valores perdidos en cada una de las variables solicitadas: total children ever born (V201), \n",
    "# Ideal number of children (V613), Husbands education-single yrs (V715), and Age at first marriage (V511)\n",
    "\n",
    "endes2019_missing = endes_2019.loc[ : ,['V201','V613','V715','V511']].isnull().sum()\n",
    "endes2019_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Después de identificar que las columnas V613 y V715 son CATEGORICAL, las convertimos a FLOAT\n",
    "endes_2019[\"V613\"] = endes_2019[\"V613\"].replace(\"Respuesta no numérica\", np.nan).astype(str).astype(float)\n",
    "endes_2019[\"V715\"] = endes_2019[\"V715\"].replace(\"No sabe\", np.nan).astype(str).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se genera un objeto que contenga las operaciones solicitadas. Para ello, se usa el método LOC para visualizar solo las variables solicitas en el ejercicio, luego se aplica la \n",
    "# función DESCRIBE para solicitar los estadísticos respectivos.\n",
    "endes_2019_1 = endes_2019.loc[:,[\"V201\",\"V613\",\"V715\",\"V511\"]].describe(include=\"all\")\n",
    "endes_2019_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificamos y Contamos los valores perdidos de nuestras variables y las agregamos a nuestra data frame\n",
    "endes_2019_1.loc[\"N_missing\"] = endes_2019.loc[:,[\"V201\",\"V613\",\"V715\",\"V511\"]].isna().sum()\n",
    "endes_2019_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luego invertimos el orden de nuestros ejes con .transpose() y re-establecemos los índices con .reset_index()\n",
    "endes_2019_2 = endes_2019_1.loc[[\"min\",\"max\",\"mean\",\"count\",\"N_missing\"]].transpose().reset_index()\n",
    "endes_2019_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiamos el nombre de nuestras variables con .rename(columns= ) y ordenamos nuestro data frame de acuerdo a los valores de\n",
    "# la columna N_missing con .sort_values()\n",
    "endes_2019_3 = endes_2019_2.rename(columns = {\"index\":\"Variables\", \"min\":\"Min\", \"max\":\"Max\",\"mean\":\"Mean\",\"count\":\"N_obs\"}).sort_values(\"N_missing\")\n",
    "endes_2019_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Use `endes_2019` data to generate a new object named `mean_key_vars` to find the mean of **total children ever born (V201)**, **Ideal number of children (V613)**, **Husbands education-single yrs (V715)**, and **Age at first marriage (V511)** by year and department **(V024)**. Name these columns as **mean_total_children, mean_ideal_children, mean_hb_yr_educ and mean_first_marriage**, respectively. **Hint: Use groupby and [this link](https://stackoverflow.com/questions/40901770/is-there-a-simple-way-to-change-a-column-of-yes-no-to-1-0-in-a-pandas-dataframe).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con la función .groupby() reagrupamos nuestro data frame según los valores de V024. Solicitamos las variables señaladas con la\n",
    "# indicación de promediar los valores agrupados. Finalmente cambiamos los nombre de nuestras columnas.\n",
    "mean_key_vars = endes_2019.groupby([\"V024\"], as_index=False)[[\"V201\",\"V613\",\"V715\",\"V511\"]].mean(\n",
    "                ).rename(columns = {\"V201\":\"mean_total_children\",\"V613\":\"mean_ideal_children\",\"V715\":\"mean_hb_yr_educ\",\"V511\":\"mean_first_marriage\"})\n",
    "mean_key_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Reshape `mean_key_vars` from wide to long. We want a dataframe with three columns **dpto, variables, values**. Name this object as `reshape_mean_key_vars`. **Hint: Use melt method**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con la función .melt() reconfiguramos el data frame mean_key_bars teniendo en cuenta los valores de V024, y asignando los\n",
    "# nombres de nuestras dos columnas como \"variables\" y \"values\". Finalmente cambiamos el nombre de V024 a dpto.\n",
    "reshape_mean_key_vars = pd.melt(mean_key_vars, id_vars = [\"V024\"], var_name = \"variables\", value_name = \"values\").rename(columns = {\"V024\":\"dpto\"})\n",
    "reshape_mean_key_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Replicate your answers for questions 7 and 8, but in one line of code. Make it the most simple as possible. **NO HINT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con la función .merge() agregamos a endes_2019 el objeto reshape_mean_key_vars con la columna dpto renombrada como V024 para \n",
    "# utilizarla como el punto de referencia para la unión.\n",
    "final_result = endes_2019.merge(reshape_mean_key_vars.rename(columns={\"dpto\":\"V024\"}), on = ['V024'], how = \"left\", validate = \"m:m\")\n",
    "final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Merge `reshape_mean_key_vars` with `endes_2019`. Name this object `final_result`. **Hint: Use merge.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con la función .merge() agregamos a endes_2019 el objeto reshape_mean_key_vars con la columna dpto renombrada como V024 para \n",
    "# utilizarla como el punto de referencia para la unión.\n",
    "final_result = endes_2019.merge(reshape_mean_key_vars.rename(columns={\"dpto\":\"V024\"}), on = ['V024'], how = \"left\", validate = \"m:m\")\n",
    "final_result"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
